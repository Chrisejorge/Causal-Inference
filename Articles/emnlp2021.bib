@Article{ahrens2021bayesian,
  author  = {Ahrens, Maximilian and Ashwin, Julian and Calliess, Jan-Peter and Nguyen, Vu},
  journal = {arXiv preprint arXiv:2109.05317},
  title   = {Bayesian Topic Regression for Causal Inference},
  year    = {2021},
  groups  = {EMNLP2021},
  url     = {https://arxiv.org/pdf/2109.05317.pdf},
}

@InProceedings{jin-etal-2021-causal,
  author    = {Jin, Zhijing and von K{\"u}gelgen, Julius and Ni, Jingwei and Vaidhya, Tejas and Kaushal, Ayush and Sachan, Mrinmaya and Schoelkopf, Bernhard},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  title     = {Causal Direction of Data Collection Matters: Implications of Causal and Anticausal Learning for {NLP}},
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  month     = nov,
  pages     = {9499--9513},
  publisher = {Association for Computational Linguistics},
  abstract  = {The principle of independent causal mechanisms (ICM) states that generative processes of real world data consist of independent modules which do not influence or inform each other. While this idea has led to fruitful developments in the field of causal inference, it is not widely-known in the NLP community. In this work, we argue that the causal direction of the data collection process bears nontrivial implications that can explain a number of published NLP findings, such as differences in semi-supervised learning (SSL) and domain adaptation (DA) performance across different settings. We categorize common NLP tasks according to their causal direction and empirically assay the validity of the ICM principle for text data using minimum description length. We conduct an extensive meta-analysis of over 100 published SSL and 30 DA studies, and find that the results are consistent with our expectations based on causal insights. This work presents the first attempt to analyze the ICM principle in NLP, and provides constructive suggestions for future modeling choices.},
  groups    = {EMNLP2021},
  url       = {https://aclanthology.org/2021.emnlp-main.748},
}

@InProceedings{chen-etal-2021-reinforced,
  author    = {Chen, Hao and Xia, Rui and Yu, Jianfei},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  title     = {Reinforced Counterfactual Data Augmentation for Dual Sentiment Classification},
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  month     = nov,
  pages     = {269--278},
  publisher = {Association for Computational Linguistics},
  abstract  = {Data augmentation and adversarial perturbation approaches have recently achieved promising results in solving the over-fitting problem in many natural language processing (NLP) tasks including sentiment classification. However, existing studies aimed to improve the generalization ability by augmenting the training data with synonymous examples or adding random noises to word embeddings, which cannot address the spurious association problem. In this work, we propose an end-to-end reinforcement learning framework, which jointly performs counterfactual data generation and dual sentiment classification. Our approach has three characteristics:1) the generator automatically generates massive and diverse antonymous sentences; 2) the discriminator contains a original-side sentiment predictor and an antonymous-side sentiment predictor, which jointly evaluate the quality of the generated sample and help the generator iteratively generate higher-quality antonymous samples; 3) the discriminator is directly used as the final sentiment classifier without the need to build an extra one. Extensive experiments show that our approach outperforms strong data augmentation baselines on several benchmark sentiment classification datasets. Further analysis confirms our approach{'}s advantages in generating more diverse training samples and solving the spurious association problem in sentiment classification.},
  groups    = {EMNLP2021},
  url       = {https://aclanthology.org/2021.emnlp-main.24},
}

@InProceedings{sen-etal-2021-counterfactually,
  author    = {Sen, Indira and Samory, Mattia and Fl{\"o}ck, Fabian and Wagner, Claudia and Augenstein, Isabelle},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  title     = {How Does Counterfactually Augmented Data Impact Models for Social Computing Constructs?},
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  month     = nov,
  pages     = {325--344},
  publisher = {Association for Computational Linguistics},
  abstract  = {As NLP models are increasingly deployed in socially situated settings such as online abusive content detection, it is crucial to ensure that these models are robust. One way of improving model robustness is to generate counterfactually augmented data (CAD) for training models that can better learn to distinguish between core features and data artifacts. While models trained on this type of data have shown promising out-of-domain generalizability, it is still unclear what the sources of such improvements are. We investigate the benefits of CAD for social NLP models by focusing on three social computing constructs {---} sentiment, sexism, and hate speech. Assessing the performance of models trained with and without CAD across different types of datasets, we find that while models trained on CAD show lower in-domain performance, they generalize better out-of-domain. We unpack this apparent discrepancy using machine explanations and find that CAD reduces model reliance on spurious features. Leveraging a novel typology of CAD to analyze their relationship with model performance, we find that CAD which acts on the construct directly or a diverse set of CAD leads to higher performance.},
  groups    = {EMNLP2021},
  url       = {https://aclanthology.org/2021.emnlp-main.28},
}

@InProceedings{falke-lehnen-2021-feedback,
  author    = {Falke, Tobias and Lehnen, Patrick},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  title     = {Feedback Attribution for Counterfactual Bandit Learning in Multi-Domain Spoken Language Understanding},
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  month     = nov,
  pages     = {1190--1198},
  publisher = {Association for Computational Linguistics},
  abstract  = {With counterfactual bandit learning, models can be trained based on positive and negative feedback received for historical predictions, with no labeled data needed. Such feedback is often available in real-world dialog systems, however, the modularized architecture commonly used in large-scale systems prevents the direct application of such algorithms. In this paper, we study the feedback attribution problem that arises when using counterfactual bandit learning for multi-domain spoken language understanding. We introduce an experimental setup to simulate the problem on small-scale public datasets, propose attribution methods inspired by multi-agent reinforcement learning and evaluate them against multiple baselines. We find that while directly using overall feedback leads to disastrous performance, our proposed attribution methods can allow training competitive models from user feedback.},
  groups    = {EMNLP2021},
  url       = {https://aclanthology.org/2021.emnlp-main.91},
}

@InProceedings{balashankar-etal-2021-improve,
  author    = {Balashankar, Ananth and Wang, Xuezhi and Packer, Ben and Thain, Nithum and Chi, Ed and Beutel, Alex},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  title     = {Can We Improve Model Robustness through Secondary Attribute Counterfactuals?},
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  month     = nov,
  pages     = {4701--4712},
  publisher = {Association for Computational Linguistics},
  abstract  = {Developing robust NLP models that perform well on many, even small, slices of data is a significant but important challenge, with implications from fairness to general reliability. To this end, recent research has explored how models rely on spurious correlations, and how counterfactual data augmentation (CDA) can mitigate such issues. In this paper we study how and why modeling counterfactuals over multiple attributes can go significantly further in improving model performance. We propose RDI, a context-aware methodology which takes into account the impact of secondary attributes on the model{'}s predictions and increases sensitivity for secondary attributes over reweighted counterfactually augmented data. By implementing RDI in the context of toxicity detection, we find that accounting for secondary attributes can significantly improve robustness, with improvements in sliced accuracy on the original dataset up to 7{\%} compared to existing robustness methods. We also demonstrate that RDI generalizes to the coreference resolution task and provide guidelines to extend this to other tasks.},
  groups    = {EMNLP2021},
  url       = {https://aclanthology.org/2021.emnlp-main.386},
}

@InProceedings{ye-etal-2021-connecting,
  author    = {Ye, Xi and Nair, Rohan and Durrett, Greg},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  title     = {Connecting Attributions and {QA} Model Behavior on Realistic Counterfactuals},
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  month     = nov,
  pages     = {5496--5512},
  publisher = {Association for Computational Linguistics},
  abstract  = {When a model attribution technique highlights a particular part of the input, a user might understand this highlight as making a statement about counterfactuals (Miller, 2019): if that part of the input were to change, the model{'}s prediction might change as well. This paper investigates how well different attribution techniques align with this assumption on realistic counterfactuals in the case of reading comprehension (RC). RC is a particularly challenging test case, as token-level attributions that have been extensively studied in other NLP tasks such as sentiment analysis are less suitable to represent the reasoning that RC models perform. We construct counterfactual sets for three different RC settings, and through heuristics that can connect attribution methods{'} outputs to high-level model behavior, we can evaluate how useful different attribution methods and even different formats are for understanding counterfactuals. We find that pairwise attributions are better suited to RC than token-level attributions across these different RC settings, with our best performance coming from a modification that we propose to an existing pairwise attribution method.},
  groups    = {EMNLP2021},
  url       = {https://aclanthology.org/2021.emnlp-main.447},
}

@InProceedings{fern-pope-2021-text,
  author    = {Fern, Xiaoli and Pope, Quintin},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  title     = {Text Counterfactuals via Latent Optimization and {S}hapley-Guided Search},
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  month     = nov,
  pages     = {5578--5593},
  publisher = {Association for Computational Linguistics},
  abstract  = {We study the problem of generating counterfactual text for a classifier as a means for understanding and debugging classification. Given a textual input and a classification model, we aim to minimally alter the text to change the model{'}s prediction. White-box approaches have been successfully applied to similar problems in vision where one can directly optimize the continuous input. Optimization-based approaches become difficult in the language domain due to the discrete nature of text. We bypass this issue by directly optimizing in the latent space and leveraging a language model to generate candidate modifications from optimized latent representations. We additionally use Shapley values to estimate the combinatoric effect of multiple changes. We then use these estimates to guide a beam search for the final counterfactual text. We achieve favorable performance compared to recent white-box and black-box baselines using human and automatic evaluations. Ablation studies show that both latent optimization and the use of Shapley values improve success rate and the quality of the generated counterfactuals.},
  groups    = {EMNLP2021},
  url       = {https://aclanthology.org/2021.emnlp-main.452},
}

@InProceedings{oneill-etal-2021-wish,
  author    = {O{'}Neill, James and Rozenshtein, Polina and Kiryo, Ryuichi and Kubota, Motoko and Bollegala, Danushka},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  title     = {{I} Wish {I} Would Have Loved This One, But {I} Didn{'}t {--} A Multilingual Dataset for Counterfactual Detection in Product Review},
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  month     = nov,
  pages     = {7092--7108},
  publisher = {Association for Computational Linguistics},
  abstract  = {Counterfactual statements describe events that did not or cannot take place. We consider the problem of counterfactual detection (CFD) in product reviews. For this purpose, we annotate a multilingual CFD dataset from Amazon product reviews covering counterfactual statements written in English, German, and Japanese languages. The dataset is unique as it contains counterfactuals in multiple languages, covers a new application area of e-commerce reviews, and provides high quality professional annotations. We train CFD models using different text representation methods and classifiers. We find that these models are robust against the selectional biases introduced due to cue phrase-based sentence selection. Moreover, our CFD dataset is compatible with prior datasets and can be merged to learn accurate CFD models. Applying machine translation on English counterfactual examples to create multilingual data performs poorly, demonstrating the language-specificity of this problem, which has been ignored so far.},
  groups    = {EMNLP2021},
  url       = {https://aclanthology.org/2021.emnlp-main.568},
}

@InProceedings{gor-etal-2021-toward,
  author    = {Gor, Maharshi and Webster, Kellie and Boyd-Graber, Jordan},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  title     = {Toward Deconfounding the Effect of Entity Demographics for Question Answering Accuracy},
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  month     = nov,
  pages     = {5457--5473},
  publisher = {Association for Computational Linguistics},
  abstract  = {The goal of question answering (QA) is to answer {\_}any{\_} question. However, major QA datasets have skewed distributions over gender, profession, and nationality. Despite that skew, an analysis of model accuracy reveals little evidence that accuracy is lower for people based on gender or nationality; instead, there is more variation on professions (question topic) and question ambiguity. But QA{'}s lack of representation could itself hide evidence of bias, necessitating QA datasets that better represent global diversity.},
  groups    = {EMNLP2021},
  url       = {https://aclanthology.org/2021.emnlp-main.444},
}

@InProceedings{hamalainen-etal-2021-finnish,
  author    = {H{\"a}m{\"a}l{\"a}inen, Mika and Alnajjar, Khalid and Partanen, Niko and Rueter, Jack},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  title     = {{F}innish Dialect Identification: The Effect of Audio and Text},
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  month     = nov,
  pages     = {8777--8783},
  publisher = {Association for Computational Linguistics},
  abstract  = {Finnish is a language with multiple dialects that not only differ from each other in terms of accent (pronunciation) but also in terms of morphological forms and lexical choice. We present the first approach to automatically detect the dialect of a speaker based on a dialect transcript and transcript with audio recording in a dataset consisting of 23 different dialects. Our results show that the best accuracy is received by combining both of the modalities, as text only reaches to an overall accuracy of 57{\%}, where as text and audio reach to 85{\%}. Our code, models and data have been released openly on Github and Zenodo.},
  groups    = {EMNLP2021},
  url       = {https://aclanthology.org/2021.emnlp-main.692},
}

@InProceedings{lian-etal-2021-effect,
  author    = {Lian, Yuchen and Bisazza, Arianna and Verhoef, Tessa},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  title     = {The Effect of Efficient Messaging and Input Variability on Neural-Agent Iterated Language Learning},
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  month     = nov,
  pages     = {10121--10129},
  publisher = {Association for Computational Linguistics},
  abstract  = {Natural languages display a trade-off among different strategies to convey syntactic structure, such as word order or inflection. This trade-off, however, has not appeared in recent simulations of iterated language learning with neural network agents (Chaabouni et al., 2019b). We re-evaluate this result in light of three factors that play an important role in comparable experiments from the Language Evolution field: (i) speaker bias towards efficient messaging, (ii) non systematic input languages, and (iii) learning bottleneck. Our simulations show that neural agents mainly strive to maintain the utterance type distribution observed during learning, instead of developing a more efficient or systematic language.},
  groups    = {EMNLP2021},
  url       = {https://aclanthology.org/2021.emnlp-main.794},
}
